{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.DataFrame(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\preprocessing\\label.py:111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "\n",
    "Y = pd.get_dummies(y1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3\n",
       "0    5.1  3.5  1.4  0.2\n",
       "1    4.9  3.0  1.4  0.2\n",
       "2    4.7  3.2  1.3  0.2\n",
       "3    4.6  3.1  1.5  0.2\n",
       "4    5.0  3.6  1.4  0.2\n",
       "5    5.4  3.9  1.7  0.4\n",
       "6    4.6  3.4  1.4  0.3\n",
       "7    5.0  3.4  1.5  0.2\n",
       "8    4.4  2.9  1.4  0.2\n",
       "9    4.9  3.1  1.5  0.1\n",
       "10   5.4  3.7  1.5  0.2\n",
       "11   4.8  3.4  1.6  0.2\n",
       "12   4.8  3.0  1.4  0.1\n",
       "13   4.3  3.0  1.1  0.1\n",
       "14   5.8  4.0  1.2  0.2\n",
       "15   5.7  4.4  1.5  0.4\n",
       "16   5.4  3.9  1.3  0.4\n",
       "17   5.1  3.5  1.4  0.3\n",
       "18   5.7  3.8  1.7  0.3\n",
       "19   5.1  3.8  1.5  0.3\n",
       "20   5.4  3.4  1.7  0.2\n",
       "21   5.1  3.7  1.5  0.4\n",
       "22   4.6  3.6  1.0  0.2\n",
       "23   5.1  3.3  1.7  0.5\n",
       "24   4.8  3.4  1.9  0.2\n",
       "25   5.0  3.0  1.6  0.2\n",
       "26   5.0  3.4  1.6  0.4\n",
       "27   5.2  3.5  1.5  0.2\n",
       "28   5.2  3.4  1.4  0.2\n",
       "29   4.7  3.2  1.6  0.2\n",
       "..   ...  ...  ...  ...\n",
       "120  6.9  3.2  5.7  2.3\n",
       "121  5.6  2.8  4.9  2.0\n",
       "122  7.7  2.8  6.7  2.0\n",
       "123  6.3  2.7  4.9  1.8\n",
       "124  6.7  3.3  5.7  2.1\n",
       "125  7.2  3.2  6.0  1.8\n",
       "126  6.2  2.8  4.8  1.8\n",
       "127  6.1  3.0  4.9  1.8\n",
       "128  6.4  2.8  5.6  2.1\n",
       "129  7.2  3.0  5.8  1.6\n",
       "130  7.4  2.8  6.1  1.9\n",
       "131  7.9  3.8  6.4  2.0\n",
       "132  6.4  2.8  5.6  2.2\n",
       "133  6.3  2.8  5.1  1.5\n",
       "134  6.1  2.6  5.6  1.4\n",
       "135  7.7  3.0  6.1  2.3\n",
       "136  6.3  3.4  5.6  2.4\n",
       "137  6.4  3.1  5.5  1.8\n",
       "138  6.0  3.0  4.8  1.8\n",
       "139  6.9  3.1  5.4  2.1\n",
       "140  6.7  3.1  5.6  2.4\n",
       "141  6.9  3.1  5.1  2.3\n",
       "142  5.8  2.7  5.1  1.9\n",
       "143  6.8  3.2  5.9  2.3\n",
       "144  6.7  3.3  5.7  2.5\n",
       "145  6.7  3.0  5.2  2.3\n",
       "146  6.3  2.5  5.0  1.9\n",
       "147  6.5  3.0  5.2  2.0\n",
       "148  6.2  3.4  5.4  2.3\n",
       "149  5.9  3.0  5.1  1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(8, input_dim=4, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(3, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "120/120 [==============================] - 12s 96ms/step - loss: 0.6543 - acc: 0.6806\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 543us/step - loss: 0.6339 - acc: 0.7000\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.6144 - acc: 0.7306\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 537us/step - loss: 0.5962 - acc: 0.7500\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 456us/step - loss: 0.5778 - acc: 0.7583\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 456us/step - loss: 0.5601 - acc: 0.7611\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.5428 - acc: 0.7667\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 473us/step - loss: 0.5253 - acc: 0.7694\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 512us/step - loss: 0.5082 - acc: 0.7722\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 546us/step - loss: 0.4925 - acc: 0.7778\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 493us/step - loss: 0.4756 - acc: 0.7861\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 534us/step - loss: 0.4584 - acc: 0.7972\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 529us/step - loss: 0.4424 - acc: 0.8083\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.4262 - acc: 0.8167\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 476us/step - loss: 0.4113 - acc: 0.8306\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 485us/step - loss: 0.3972 - acc: 0.8528\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.3827 - acc: 0.8611\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.3698 - acc: 0.8694\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.3575 - acc: 0.8667\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.3460 - acc: 0.8694\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.3349 - acc: 0.8722\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 434us/step - loss: 0.3251 - acc: 0.8667\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.3157 - acc: 0.8667\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.3070 - acc: 0.8694\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 443us/step - loss: 0.2988 - acc: 0.8694\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 543us/step - loss: 0.2912 - acc: 0.8694\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 543us/step - loss: 0.2844 - acc: 0.8722\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.2780 - acc: 0.8750\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 485us/step - loss: 0.2722 - acc: 0.8750\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 434us/step - loss: 0.2664 - acc: 0.8750\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 443us/step - loss: 0.2611 - acc: 0.8806\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.2559 - acc: 0.8861\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.2510 - acc: 0.8861\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.2464 - acc: 0.8889\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.2421 - acc: 0.8944\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.2379 - acc: 0.8972\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.2339 - acc: 0.8972\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.2300 - acc: 0.8972\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 485us/step - loss: 0.2263 - acc: 0.9000\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 501us/step - loss: 0.2229 - acc: 0.9000\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 485us/step - loss: 0.2194 - acc: 0.9000\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 526us/step - loss: 0.2163 - acc: 0.9056\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 476us/step - loss: 0.2130 - acc: 0.9056\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 526us/step - loss: 0.2100 - acc: 0.9083\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 476us/step - loss: 0.2071 - acc: 0.9083\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.2041 - acc: 0.9139\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 501us/step - loss: 0.2015 - acc: 0.9139\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1989 - acc: 0.9139\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 443us/step - loss: 0.1965 - acc: 0.9167\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 493us/step - loss: 0.1938 - acc: 0.9222\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 493us/step - loss: 0.1915 - acc: 0.9222\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1892 - acc: 0.9222\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 476us/step - loss: 0.1868 - acc: 0.9222\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.1846 - acc: 0.9222\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1822 - acc: 0.9250\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 443us/step - loss: 0.1802 - acc: 0.9278\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1781 - acc: 0.9278\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1758 - acc: 0.9333\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1738 - acc: 0.9333\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 476us/step - loss: 0.1719 - acc: 0.9361\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1700 - acc: 0.9361\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.1680 - acc: 0.9361\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 443us/step - loss: 0.1660 - acc: 0.9361\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1643 - acc: 0.9361\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1625 - acc: 0.9389\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1607 - acc: 0.9389\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1590 - acc: 0.9389\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 443us/step - loss: 0.1572 - acc: 0.9389\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 434us/step - loss: 0.1555 - acc: 0.9389\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 476us/step - loss: 0.1537 - acc: 0.9389\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.1523 - acc: 0.9444\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1507 - acc: 0.9444\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1489 - acc: 0.9444\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1474 - acc: 0.9444\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1457 - acc: 0.9444\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1440 - acc: 0.9472\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1427 - acc: 0.9472\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1412 - acc: 0.9472\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1395 - acc: 0.9500\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 493us/step - loss: 0.1382 - acc: 0.9500\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1364 - acc: 0.9500\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 468us/step - loss: 0.1349 - acc: 0.9500\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 0s 451us/step - loss: 0.1335 - acc: 0.9556\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 460us/step - loss: 0.1322 - acc: 0.9583\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 568us/step - loss: 0.1307 - acc: 0.9583\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 551us/step - loss: 0.1292 - acc: 0.9583\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 451us/step - loss: 0.1278 - acc: 0.9583\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 378us/step - loss: 0.1264 - acc: 0.9583\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 478us/step - loss: 0.1252 - acc: 0.9583\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1237 - acc: 0.9583\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1224 - acc: 0.9583\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1211 - acc: 0.9583\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1202 - acc: 0.9583\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 417us/step - loss: 0.1188 - acc: 0.9611\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 423us/step - loss: 0.1174 - acc: 0.9611\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1162 - acc: 0.9611\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 387us/step - loss: 0.1150 - acc: 0.9611\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 481us/step - loss: 0.1138 - acc: 0.9611\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 418us/step - loss: 0.1125 - acc: 0.9611\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 426us/step - loss: 0.1115 - acc: 0.9639\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x3fd4d4b2e8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "ypred_max=np.argmax(ypred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypred_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_max=np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        11\n",
      "          1       1.00      1.00      1.00        13\n",
      "          2       1.00      1.00      1.00         6\n",
      "\n",
      "avg / total       1.00      1.00      1.00        30\n",
      "\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test_max,ypred_max))\n",
    "print(confusion_matrix(y_test_max,ypred_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
