{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(128, 128,...)`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Conv2D(32, 3, 3, input_shape=(128,128,3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Conv2D(32, 3, 3,  activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(32, 3, 3,  activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "classifier.add(Conv2D(32, 3, 3,  activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, activation=\"relu\")`\n",
      "  \n",
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=128, activation=\"relu\")`\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:5: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "classifier.add(Dense(output_dim=128, activation='relu'))\n",
    "classifier.add(Dropout(p=0.1))\n",
    "classifier.add(Dense(output_dim=128, activation='relu'))\n",
    "classifier.add(Dropout(p=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, activation=\"sigmoid\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n",
      "Epoch 1/25\n",
      "250/250 [==============================] - 185s 739ms/step - loss: 0.6861 - acc: 0.5509 - val_loss: 0.6532 - val_acc: 0.6331\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 189s 755ms/step - loss: 0.6227 - acc: 0.6544 - val_loss: 0.6127 - val_acc: 0.6809\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 205s 819ms/step - loss: 0.5731 - acc: 0.7061 - val_loss: 0.5583 - val_acc: 0.7200\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 194s 774ms/step - loss: 0.5341 - acc: 0.7337 - val_loss: 0.5172 - val_acc: 0.7525\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 194s 775ms/step - loss: 0.5062 - acc: 0.7504 - val_loss: 0.5160 - val_acc: 0.7444\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 199s 795ms/step - loss: 0.4798 - acc: 0.7732 - val_loss: 0.4689 - val_acc: 0.7886\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 202s 807ms/step - loss: 0.4659 - acc: 0.7702 - val_loss: 0.4499 - val_acc: 0.7927\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 203s 812ms/step - loss: 0.4544 - acc: 0.7815 - val_loss: 0.4336 - val_acc: 0.8018\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 202s 807ms/step - loss: 0.4397 - acc: 0.7993 - val_loss: 0.4495 - val_acc: 0.8054\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 168s 671ms/step - loss: 0.4264 - acc: 0.8039 - val_loss: 0.4497 - val_acc: 0.7891\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 175s 699ms/step - loss: 0.4090 - acc: 0.8161 - val_loss: 0.4365 - val_acc: 0.8115\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 181s 724ms/step - loss: 0.3927 - acc: 0.8220 - val_loss: 0.4178 - val_acc: 0.8140\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 184s 736ms/step - loss: 0.3829 - acc: 0.8267 - val_loss: 0.4173 - val_acc: 0.8135\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 192s 768ms/step - loss: 0.3696 - acc: 0.8350 - val_loss: 0.4422 - val_acc: 0.7957\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 182s 728ms/step - loss: 0.3608 - acc: 0.8413 - val_loss: 0.4120 - val_acc: 0.8272\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 182s 729ms/step - loss: 0.3539 - acc: 0.8409 - val_loss: 0.4440 - val_acc: 0.8018\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 183s 733ms/step - loss: 0.3479 - acc: 0.8494 - val_loss: 0.3886 - val_acc: 0.8288\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 179s 715ms/step - loss: 0.3267 - acc: 0.8600 - val_loss: 0.3943 - val_acc: 0.8252\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 178s 713ms/step - loss: 0.3432 - acc: 0.8502 - val_loss: 0.4070 - val_acc: 0.8196\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 205s 819ms/step - loss: 0.3095 - acc: 0.8660 - val_loss: 0.3736 - val_acc: 0.8410\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 187s 749ms/step - loss: 0.3042 - acc: 0.8664 - val_loss: 0.3847 - val_acc: 0.8374\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 202s 806ms/step - loss: 0.2996 - acc: 0.8669 - val_loss: 0.4112 - val_acc: 0.8343\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 168s 673ms/step - loss: 0.3000 - acc: 0.8707 - val_loss: 0.3584 - val_acc: 0.8460\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 181s 725ms/step - loss: 0.2865 - acc: 0.8786 - val_loss: 0.3347 - val_acc: 0.8567\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 166s 664ms/step - loss: 0.2688 - acc: 0.8837 - val_loss: 0.4307 - val_acc: 0.8272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1817e8fed0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\n",
    "                                                    'dataset/training_set',\n",
    "                                                    target_size=(128, 128),\n",
    "                                                    batch_size=32,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory(\n",
    "                                                        'dataset/test_set',\n",
    "                                                        target_size=(128, 128),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode='binary')\n",
    "\n",
    "classifier.fit_generator(\n",
    "        train_set,\n",
    "        steps_per_epoch=8000/32,\n",
    "        epochs=25,\n",
    "        validation_data=validation_set,\n",
    "        validation_steps=2000/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('dataset/single_prediction/cat_or_dog_1.jpg', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 57,  60,   7],\n",
       "         [ 57,  60,   7],\n",
       "         [ 57,  60,   7],\n",
       "         ..., \n",
       "         [231, 201, 175],\n",
       "         [228, 200, 176],\n",
       "         [228, 200, 176]]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "pix_val = list(im.getdata())\n",
    "pix_val = np.asarray(pix_val)\n",
    "pix_val = np.expand_dims(pix_val, axis = 0)\n",
    "pix_val = np.expand_dims(pix_val, axis = 0)\n",
    "pix_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (1, 691200, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ea1d51584d04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpix_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1823\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maxim/anaconda3/envs/tensorflow/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    111\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected conv2d_1_input to have 4 dimensions, but got array with shape (1, 691200, 3)"
     ]
    }
   ],
   "source": [
    "img_class = classifier.predict(pix_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dataset/single_prediction/cat_or_dog_2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(result[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
